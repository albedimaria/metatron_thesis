Index: ../README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># EssentialSounds: Innovative 3D Music Sample Filtering\r\n## Reimagine Music Interaction and Visualization in Real-time with React\r\n\r\nEssentialSounds is a project that aims to change the way we visualize music samples. This repository houses the groundbreaking codebase that combines \r\nthe power of Python's backend with React's frontend to bring you unparalleled 3D music sample visualization and an innovative filtering system.\r\nThe main features of this project are the following:\r\n\r\n* complete feature extraction using Essentia library\r\n* new way of real-time filtering based on extracted features\r\n* new 3D way of visualizing music samples: each axis displays a feature chosen by the user\r\n* large set of available features for a unique and customised experience \r\n* possibility to handle up to 50 samples simultaneously without losing performance\r\n\r\n## how the project appears\r\n\r\n### overall view (hidden filters section)\r\n<img width=\"1040\" alt=\"whole\" src=\"https://github.com/albedimaria/frontend-thesis/assets/74492752/f0f5a97e-3caa-4662-a852-7d0c7a74fee2\">\r\n\r\n### filters section\r\n<img width=\"192\" alt=\"filters\" src=\"https://github.com/albedimaria/frontend-thesis/assets/74492752/0af92c35-826d-4123-89f6-0150679722b0\">\r\n\r\n### more in detail\r\n<img width=\"184\" alt=\"filters in detail\" src=\"https://github.com/albedimaria/frontend-thesis/assets/74492752/a3db896b-9201-4fc2-a72a-04f85664cbf1\">\r\n\r\n\r\n## working in progress \r\n* connection back / front ends through socket.io-client\r\n* isPlaying / isSelected sphere and what it should do\r\n* json used to link front / back ends (fast and not volatile)\r\n* loader to handle the processing of samples at the beginning\r\n\r\n## artistic direction choices to make:\r\n* spheres representing brief samples or long / processed loops\r\n* play the sample when the sphere is clicked / send the sample to Ableton\r\n\r\n\r\n## further improvements \r\n* addictional server front-end / external daw\r\n* loader at the beginning\r\n* connection with another device (another server needed)\r\n* drag and drop to add more samples while running the system\r\n* instructions for the user through a pop-up\r\n\r\n  \r\n## known issues (to be solved)\r\n* the first instance of the sphere is repeated four times due to the implementation. Should be just one (black box UX)\r\n* The features on this axis cannot be freely chosen; it was necessary to split them manually (black box UX)\r\n* The colors are not under control; they appear or do not appear randomly. The colors should always be visible (white box UX)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/../README.md b/../README.md
--- a/../README.md	
+++ b/../README.md	
@@ -2,14 +2,17 @@
 ## Reimagine Music Interaction and Visualization in Real-time with React
 
 EssentialSounds is a project that aims to change the way we visualize music samples. This repository houses the groundbreaking codebase that combines 
-the power of Python's backend with React's frontend to bring you unparalleled 3D music sample visualization and an innovative filtering system.
+the power of Python's backend with React-3-Fiber's frontend to bring you unparalleled 3D music sample visualization and an innovative filtering system.
 The main features of this project are the following:
 
 * complete feature extraction using Essentia library
+* new 3D way of visualizing music samples with R3F
+* new way to organize the dataset: each axis displays a feature chosen by the user
 * new way of real-time filtering based on extracted features
-* new 3D way of visualizing music samples: each axis displays a feature chosen by the user
 * large set of available features for a unique and customised experience 
-* possibility to handle up to 50 samples simultaneously without losing performance
+* possibility to handle up to 50* samples simultaneously without losing performance (*now 300)
+* responsive (to be tested for optimized UX)
+* easy, intuitive and guided UX
 
 ## how the project appears
 
@@ -22,6 +25,21 @@
 ### more in detail
 <img width="184" alt="filters in detail" src="https://github.com/albedimaria/frontend-thesis/assets/74492752/a3db896b-9201-4fc2-a72a-04f85664cbf1">
 
+## filter section
+* features involved
+  - BPM
+  - Danceability
+  - Mood
+  - Texture (work in progress)
+  - Instrument
+  - Key
+* the choice to not provide the genre as an available feature aims to focus on the other meta descriptors.
+* the set of features will be enlarged
+* BPM, danceability and layers of texture can be selected through a double slider, which sets the range
+* instrument, key and mood can be selected using an intuitive dropbox
+* possibility to filter by name of the samples
+* the user can choose the name of the samples between the real sample name or a feature name (such as "sad - piano - 90BPM")
+* filtering will be done in real time; it will re-render the spheres due to the code logic, but it will be a black-box approach for the user
 
 ## working in progress 
 * connection back / front ends through socket.io-client
